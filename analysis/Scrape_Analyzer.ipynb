{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iGEM Wiki Scrape Analyzer\n",
    "\n",
    "A Jupyter notebook that analyzes information pulled down by the igem-wikiscraper tool.\n",
    "\n",
    "Dependencies:\n",
    "- pandas\n",
    "- qgrid\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import qgrid\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapefile = open('output/descriptions_7-3-2018.csv', 'r')\n",
    "#scrapereader = csv.reader(scrapefile, delimiter='|', quotechar='\"')\n",
    "scrapeframe = pd.read_csv(scrapefile, delimiter='|', quotechar='\"') # read in CSV file\n",
    "scrapeframe = scrapeframe.fillna('') # Replace NaNs with empty strings\n",
    "\n",
    "keywords = [\n",
    "    \"ai2\",\n",
    "    \"quorum\",\n",
    "    \"autoinduction\",\n",
    "    \"biomanufacturing\",\n",
    "    \"lsr\",\n",
    "    \"w3110\"\n",
    "]\n",
    "patterns = [\n",
    "    r\"ai-?2\", #find anything that looks like \"ai2\" or \"ai-2\"\n",
    "    r\"quor(um|a) ?sens(ing|or|e)\",\n",
    "    r\"autoinduc(er|tion|es|ed|t)\",\n",
    "    r\"(bio)?manufactur(e|ing|er)\",\n",
    "    r\"lsr\",\n",
    "    r\"w3110\"\n",
    "]\n",
    "patterns = [re.compile(x, re.IGNORECASE) for x in patterns]\n",
    "kpdict = dict(zip(keywords, patterns))\n",
    "\n",
    "# Generates a series of two new columns which can be concatenated onto the original\n",
    "# dataframe\n",
    "def countmatches(item1, item2):\n",
    "    keywordlist = []\n",
    "    matches = 0\n",
    "    for key, pattern in kpdict.items():\n",
    "        matchitem1 = pattern.findall(item1, re.IGNORECASE)\n",
    "        matchitem2 = pattern.findall(item2, re.IGNORECASE)\n",
    "        if len(matchitem1) > 0 or len(matchitem2) > 0:\n",
    "            keywordlist.append(key)\n",
    "        matches += len(matchitem1) + len(matchitem2)\n",
    "    keywordjoin = ', '.join(keywordlist)\n",
    "    return pd.Series({'Matches':matches, 'Keywords':keywordjoin})\n",
    "\n",
    "# Apply countmatches to columns 'Homepage' and '/Description'\n",
    "scrapeframe = pd.concat([scrapeframe, scrapeframe.apply(lambda row: countmatches(row['Homepage'], row['/Description']), axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710e82a45a07481388f6299e1190b5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'rowHeight': 28, 'fullWidthRows': True, 'highlightSelectedCell': False, 'minVisibleRâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qgrid_widget = qgrid.show_grid(scrapeframe, show_toolbar=True)\n",
    "qgrid_widget"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
